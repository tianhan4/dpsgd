{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: 2021/03/14\n",
    "# Usage: Dp analysis of mnist neural network.\n",
    "# Detail: Check the notion notes in HE-DP project.\n",
    "\n",
    "from dpsgd_keras_slow import *\n",
    "\n",
    "dpsgd = False # add dp noise or not \n",
    "learning_rate = 0.05\n",
    "noise_multiplier = 8\n",
    "l2_norm_clip = 3\n",
    "batch_size = 1024\n",
    "epochs = 500\n",
    "microbatch_size = 16\n",
    "num_parameters = 0\n",
    "privacy_budget = []\n",
    "delta = 1e-5  # it is recommended to use delta~=1/dataset_size\n",
    "model_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7,8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "  \"\"\"Loads MNIST and preprocesses to combine training and validation data.\"\"\"\n",
    "  train, test = tf.keras.datasets.cifar10.load_data()\n",
    "  train_data, train_labels = train\n",
    "  test_data, test_labels = test\n",
    "\n",
    "  train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "  test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "  train_data = train_data.reshape((train_data.shape[0], 32, 32, 3))\n",
    "  test_data = test_data.reshape((test_data.shape[0], 32, 32, 3))\n",
    "\n",
    "  train_labels = np.array(train_labels, dtype=np.int32)\n",
    "  test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "  assert train_data.min() == 0.\n",
    "  assert train_data.max() == 1.\n",
    "  assert test_data.min() == 0.\n",
    "  assert test_data.max() == 1.\n",
    "\n",
    "  return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturnbing the input dataset, and collect the accuracy-step\n",
    "class GaussianNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, l2_norm_clip, noise_multiplier, *args, **kwargs):\n",
    "        super(GaussianNoiseLayer, self).__init__(*args, **kwargs)\n",
    "        self._l2_norm_clip = l2_norm_clip\n",
    "        self._noise_multiplier = noise_multiplier\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Clip gradients to given l2_norm_clip.\n",
    "        def clip_features(x):\n",
    "            return tf.clip_by_global_norm([x], self._l2_norm_clip)[0][0]\n",
    "\n",
    "        clipped_features = tf.map_fn(clip_features, x)\n",
    "        \n",
    "        # Add noise to summed gradients.\n",
    "        noise_stddev = self._l2_norm_clip * self._noise_multiplier\n",
    "        noise = tf.random.normal(tf.shape(input=clipped_features), stddev=noise_stddev)\n",
    "        return clipped_features + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.clip_by_global_norm([tf.Variable([[2,3],[4,5]],shape=[2,2],dtype=tf.float32)], 4.4)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models \n",
    "\n",
    "\n",
    "\n",
    "def build_models(noise_layer_name):\n",
    "    if noise_layer_name ==\"cifar10+untied_bias+noise_input\":\n",
    "        model = tf.keras.Sequential([\n",
    "            GaussianNoiseLayer(l2_norm_clip, noise_multiplier, input_shape=(32, 32, 3)),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "            BiasLayer()\n",
    "        ])\n",
    "    elif noise_layer_name == \"cifar10+tied_bias+noise_input\":\n",
    "        model = tf.keras.Sequential([\n",
    "            GaussianNoiseLayer(l2_norm_clip, noise_multiplier, input_shape=(32, 32, 3)),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "            BiasLayer()\n",
    "        ])\n",
    "    elif noise_layer_name == \"cifar10+untied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "            BiasLayer()\n",
    "        ])\n",
    "#     elif noise_layer_name == \"cifar10+tied_bias\":\n",
    "#             model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Conv2D(16, 5,\n",
    "#                                  strides=1,\n",
    "#                                  padding='valid',\n",
    "#                                  activation=None,\n",
    "#                                  input_shape=(32, 32, 3), use_bias=False),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Conv2D(16, 5,\n",
    "#                                  strides=1,\n",
    "#                                  padding='valid',\n",
    "#                                  activation=None, use_bias=False),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(100, activation=None, use_bias=False),\n",
    "#             BiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "#             BiasLayer()\n",
    "#         ])\n",
    "    elif noise_layer_name == \"cifar10+tied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            TiedBiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "            BiasLayer()\n",
    "        ])\n",
    "    elif noise_layer_name == \"cifar10\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False),\n",
    "            BiasLayer()\n",
    "        ])  \n",
    "    elif noise_layer_name == \"sphinx+cifar10+untied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered2\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered3\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered4\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered5\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered6\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered7\"),\n",
    "            BiasLayer(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered8\"),\n",
    "            BiasLayer()\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    elif noise_layer_name == \"sphinx+cifar10+tied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, 5,\n",
    "                             strides=1,\n",
    "                             padding='valid',\n",
    "                             activation=None,\n",
    "                             input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "        TiedBiasLayer(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "        tf.keras.layers.Conv2D(16, 5,\n",
    "                             strides=1,\n",
    "                             padding='valid',\n",
    "                             activation=None, use_bias=False, name=\"Considered2\"),\n",
    "        TiedBiasLayer(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=None, use_bias=False, name=\"Considered3\"),\n",
    "        BiasLayer(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered4\"),\n",
    "        BiasLayer()\n",
    "    ])\n",
    "#     elif noise_layer_name == \"sphinx+cifar10+tied_bias\":\n",
    "#         model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None,\n",
    "#                                  input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered2\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered3\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered4\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered5\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 1,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered6\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(16, 1,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered7\"),\n",
    "#             TiedBiasLayer(),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered8\"),\n",
    "#             BiasLayer()\n",
    "#         ])\n",
    "    elif noise_layer_name == \"ALLnoise+cifar10+untied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "            BiasLayer(name=\"Considered9\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered2\"),\n",
    "            BiasLayer(name=\"Considered10\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered3\"),\n",
    "            BiasLayer(name=\"Considered11\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered4\"),\n",
    "            BiasLayer(name=\"Considered12\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(64, 3,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered5\"),\n",
    "            BiasLayer(name=\"Considered13\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered6\"),\n",
    "            BiasLayer(name=\"Considered14\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(16, 1,\n",
    "                                 strides=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None, use_bias=False, name=\"Considered7\"),\n",
    "            BiasLayer(name=\"Considered15\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered8\"),\n",
    "            BiasLayer(name=\"Considered16\")\n",
    "        ])\n",
    "    elif noise_layer_name == \"ALLnoise+cifar10+tied_bias\":\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, 5,\n",
    "                                 strides=1,\n",
    "                                 padding='valid',\n",
    "                                 activation=None,\n",
    "                                 input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "            TiedBiasLayer(name=\"Considered7\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Conv2D(16, 5,\n",
    "                                 strides=1,\n",
    "                                 padding='valid',\n",
    "                                 activation=None, use_bias=False, name=\"Considered2\"),\n",
    "            TiedBiasLayer(name=\"Considered8\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(100, activation=None, use_bias=False, name=\"Considered3\"),\n",
    "            BiasLayer(name=\"Considered4\"),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered5\"),\n",
    "            BiasLayer(name=\"Considered6\")\n",
    "         ])\n",
    "#     elif noise_layer_name == \"ALLnoise+cifar10+tied_bias\":\n",
    "#         model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None,\n",
    "#                                  input_shape=(32, 32, 3), use_bias=False, name=\"Considered1\"),\n",
    "#             TiedBiasLayer(name=\"Considered9\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered2\"),\n",
    "#             TiedBiasLayer(name=\"Considered10\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered3\"),\n",
    "#             TiedBiasLayer(name=\"Considered11\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered4\"),\n",
    "#             TiedBiasLayer(name=\"Considered12\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.MaxPool2D((2,2), 2),\n",
    "#             tf.keras.layers.Conv2D(64, 3,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered5\"),\n",
    "#             TiedBiasLayer(name=\"Considered13\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(64, 1,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered6\"),\n",
    "#             TiedBiasLayer(name=\"Considered14\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Conv2D(16, 1,\n",
    "#                                  strides=1,\n",
    "#                                  padding='same',\n",
    "#                                  activation=None, use_bias=False, name=\"Considered7\"),\n",
    "#             TiedBiasLayer(name=\"Considered15\"),\n",
    "#             tf.keras.layers.ReLU(),\n",
    "#             tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(10, activation=None, use_bias=False, name=\"Considered8\"),\n",
    "#             BiasLayer(name=\"Considered16\")\n",
    "#         ])\n",
    "    else:\n",
    "        model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_layer (Gaussi (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1728      \n",
      "_________________________________________________________________\n",
      "bias_layer (BiasLayer)       (None, 32, 32, 64)        65536     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_1 (BiasLayer)     (None, 32, 32, 64)        65536     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_2 (BiasLayer)     (None, 16, 16, 64)        16384     \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_3 (BiasLayer)     (None, 16, 16, 64)        16384     \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_4 (BiasLayer)     (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "bias_layer_5 (BiasLayer)     (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "bias_layer_6 (BiasLayer)     (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                10240     \n",
      "_________________________________________________________________\n",
      "bias_layer_7 (BiasLayer)     (None, 10)                10        \n",
      "=================================================================\n",
      "Total params: 337,610\n",
      "Trainable params: 337,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_models(\"cifar10+untied_bias+noise_input\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        1728      \n",
      "_________________________________________________________________\n",
      "bias_layer_8 (BiasLayer)     (None, 32, 32, 64)        65536     \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_9 (BiasLayer)     (None, 32, 32, 64)        65536     \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_10 (BiasLayer)    (None, 16, 16, 64)        16384     \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_11 (BiasLayer)    (None, 16, 16, 64)        16384     \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 64)          36864     \n",
      "_________________________________________________________________\n",
      "bias_layer_12 (BiasLayer)    (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "bias_layer_13 (BiasLayer)    (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "bias_layer_14 (BiasLayer)    (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10240     \n",
      "_________________________________________________________________\n",
      "bias_layer_15 (BiasLayer)    (None, 10)                10        \n",
      "=================================================================\n",
      "Total params: 337,610\n",
      "Trainable params: 337,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_models(\"cifar10+untied_bias\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 64)        1728      \n",
      "_________________________________________________________________\n",
      "tied_bias_layer (TiedBiasLay (None, 32, 32, 64)        64        \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        36864     \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_1 (TiedBiasL (None, 32, 32, 64)        64        \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_2 (TiedBiasL (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_3 (TiedBiasL (None, 16, 16, 64)        64        \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36864     \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_4 (TiedBiasL (None, 8, 8, 64)          64        \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_5 (TiedBiasL (None, 8, 8, 64)          64        \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "tied_bias_layer_6 (TiedBiasL (None, 8, 8, 16)          16        \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10240     \n",
      "_________________________________________________________________\n",
      "bias_layer_16 (BiasLayer)    (None, 10)                10        \n",
      "=================================================================\n",
      "Total params: 164,954\n",
      "Trainable params: 164,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_models(\"cifar10+tied_bias\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 64)        1728      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 64)        36864     \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 64)          36864     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 64)          4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 16)          1024      \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10240     \n",
      "_________________________________________________________________\n",
      "bias_layer_17 (BiasLayer)    (None, 10)                10        \n",
      "=================================================================\n",
      "Total params: 164,554\n",
      "Trainable params: 164,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_models(\"cifar10\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main_simple(unused_argv):\n",
    "logging.set_verbosity(logging.INFO)\n",
    "if dpsgd and batch_size % microbatch_size != 0:\n",
    "    raise ValueError('Number of microbatches should divide evenly batch_size')\n",
    "\n",
    "# Load training and test data.\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10()\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=(epochs * train_data.shape[0]) // microbatch_size // 1000,\n",
    "    decay_rate=0.998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "49/49 [==============================] - 8s 67ms/step - loss: 2.3020 - accuracy: 0.1198 - val_loss: 2.2996 - val_accuracy: 0.1157\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.2958 - accuracy: 0.1547 - val_loss: 2.2903 - val_accuracy: 0.1421\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 2.2740 - accuracy: 0.1875 - val_loss: 2.2435 - val_accuracy: 0.1709\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2098 - accuracy: 0.2013 - val_loss: 2.1346 - val_accuracy: 0.2502\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.1028 - accuracy: 0.2499 - val_loss: 2.0040 - val_accuracy: 0.2924\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.0428 - accuracy: 0.2702 - val_loss: 2.4428 - val_accuracy: 0.1673\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.0237 - accuracy: 0.2774 - val_loss: 1.9270 - val_accuracy: 0.3080\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.9593 - accuracy: 0.3039 - val_loss: 1.8501 - val_accuracy: 0.3472\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.9182 - accuracy: 0.3159 - val_loss: 1.9723 - val_accuracy: 0.2969\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.8542 - accuracy: 0.3401 - val_loss: 1.8646 - val_accuracy: 0.3435\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.8100 - accuracy: 0.3561 - val_loss: 1.8420 - val_accuracy: 0.3527\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.7665 - accuracy: 0.3722 - val_loss: 1.7439 - val_accuracy: 0.3742\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.7360 - accuracy: 0.3826 - val_loss: 1.6793 - val_accuracy: 0.4054\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.6944 - accuracy: 0.3961 - val_loss: 1.5992 - val_accuracy: 0.4341\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.6692 - accuracy: 0.4072 - val_loss: 1.6184 - val_accuracy: 0.4273\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.6365 - accuracy: 0.4134 - val_loss: 1.7782 - val_accuracy: 0.3806\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.6134 - accuracy: 0.4240 - val_loss: 1.5330 - val_accuracy: 0.4518\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.5784 - accuracy: 0.4333 - val_loss: 1.5079 - val_accuracy: 0.4648\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.5637 - accuracy: 0.4417 - val_loss: 1.5106 - val_accuracy: 0.4651\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.5282 - accuracy: 0.4535 - val_loss: 1.5260 - val_accuracy: 0.4533\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.5103 - accuracy: 0.4603 - val_loss: 1.4770 - val_accuracy: 0.4758\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.4812 - accuracy: 0.4710 - val_loss: 1.4711 - val_accuracy: 0.4760\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.4738 - accuracy: 0.4740 - val_loss: 1.4785 - val_accuracy: 0.4771\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.4407 - accuracy: 0.4837 - val_loss: 1.5223 - val_accuracy: 0.4591\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.4279 - accuracy: 0.4910 - val_loss: 1.4083 - val_accuracy: 0.4927\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.4106 - accuracy: 0.4970 - val_loss: 1.3761 - val_accuracy: 0.5062\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.3942 - accuracy: 0.5000 - val_loss: 1.3662 - val_accuracy: 0.5120\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.3739 - accuracy: 0.5092 - val_loss: 1.3430 - val_accuracy: 0.5189\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.3630 - accuracy: 0.5153 - val_loss: 1.3378 - val_accuracy: 0.5217\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.3348 - accuracy: 0.5263 - val_loss: 1.3286 - val_accuracy: 0.5247\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.3254 - accuracy: 0.5271 - val_loss: 1.3415 - val_accuracy: 0.5199\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.3067 - accuracy: 0.5351 - val_loss: 1.2689 - val_accuracy: 0.5472\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.2929 - accuracy: 0.5403 - val_loss: 1.3062 - val_accuracy: 0.5329\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.2731 - accuracy: 0.5476 - val_loss: 1.3493 - val_accuracy: 0.5207\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.2562 - accuracy: 0.5538 - val_loss: 1.3181 - val_accuracy: 0.5280\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.2488 - accuracy: 0.5546 - val_loss: 1.2248 - val_accuracy: 0.5607\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.2221 - accuracy: 0.5662 - val_loss: 1.2183 - val_accuracy: 0.5643\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.2122 - accuracy: 0.5664 - val_loss: 1.2032 - val_accuracy: 0.5727\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.2034 - accuracy: 0.5734 - val_loss: 1.2225 - val_accuracy: 0.5615\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.1821 - accuracy: 0.5805 - val_loss: 1.1577 - val_accuracy: 0.5878\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1622 - accuracy: 0.5874 - val_loss: 1.2213 - val_accuracy: 0.5662\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.1541 - accuracy: 0.5897 - val_loss: 1.2187 - val_accuracy: 0.5643\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.1355 - accuracy: 0.5944 - val_loss: 1.1475 - val_accuracy: 0.5892\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.1329 - accuracy: 0.5978 - val_loss: 1.1152 - val_accuracy: 0.6015\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.1044 - accuracy: 0.6078 - val_loss: 1.1150 - val_accuracy: 0.6026\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0972 - accuracy: 0.6112 - val_loss: 1.1479 - val_accuracy: 0.5921\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0746 - accuracy: 0.6186 - val_loss: 1.1905 - val_accuracy: 0.5827\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0711 - accuracy: 0.6225 - val_loss: 1.0678 - val_accuracy: 0.6216\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0534 - accuracy: 0.6280 - val_loss: 1.1560 - val_accuracy: 0.5922\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.0438 - accuracy: 0.6314 - val_loss: 1.0551 - val_accuracy: 0.6275\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.0355 - accuracy: 0.6342 - val_loss: 1.0642 - val_accuracy: 0.6271\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.0216 - accuracy: 0.6408 - val_loss: 1.0792 - val_accuracy: 0.6151\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.0030 - accuracy: 0.6485 - val_loss: 1.0772 - val_accuracy: 0.6267\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.9923 - accuracy: 0.6510 - val_loss: 1.0677 - val_accuracy: 0.6251\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9814 - accuracy: 0.6546 - val_loss: 1.0249 - val_accuracy: 0.6347\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9672 - accuracy: 0.6599 - val_loss: 1.1084 - val_accuracy: 0.6068\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9645 - accuracy: 0.6608 - val_loss: 0.9998 - val_accuracy: 0.6538\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9455 - accuracy: 0.6688 - val_loss: 1.0218 - val_accuracy: 0.6428\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9356 - accuracy: 0.6710 - val_loss: 0.9931 - val_accuracy: 0.6503\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9287 - accuracy: 0.6719 - val_loss: 0.9975 - val_accuracy: 0.6526\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.9184 - accuracy: 0.6801 - val_loss: 1.0608 - val_accuracy: 0.6248\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.9129 - accuracy: 0.6783 - val_loss: 1.0181 - val_accuracy: 0.6444\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8924 - accuracy: 0.6860 - val_loss: 0.9633 - val_accuracy: 0.6617\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8952 - accuracy: 0.6853 - val_loss: 0.9727 - val_accuracy: 0.6577\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8749 - accuracy: 0.6963 - val_loss: 1.0159 - val_accuracy: 0.6449\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8723 - accuracy: 0.6944 - val_loss: 0.9849 - val_accuracy: 0.6556\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8525 - accuracy: 0.7020 - val_loss: 0.9505 - val_accuracy: 0.6700\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8577 - accuracy: 0.7006 - val_loss: 1.0302 - val_accuracy: 0.6503\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8455 - accuracy: 0.7061 - val_loss: 1.0284 - val_accuracy: 0.6421\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8345 - accuracy: 0.7076 - val_loss: 0.9166 - val_accuracy: 0.6848\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8284 - accuracy: 0.7115 - val_loss: 0.9544 - val_accuracy: 0.6643\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8116 - accuracy: 0.7166 - val_loss: 0.9289 - val_accuracy: 0.6766\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8058 - accuracy: 0.7180 - val_loss: 0.9251 - val_accuracy: 0.6774\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8076 - accuracy: 0.7188 - val_loss: 0.9416 - val_accuracy: 0.6692\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7949 - accuracy: 0.7228 - val_loss: 0.9047 - val_accuracy: 0.6854\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.7868 - accuracy: 0.7253 - val_loss: 0.9239 - val_accuracy: 0.6795\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7727 - accuracy: 0.7302 - val_loss: 0.9092 - val_accuracy: 0.6874\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7724 - accuracy: 0.7336 - val_loss: 0.9648 - val_accuracy: 0.6748\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7758 - accuracy: 0.7297 - val_loss: 0.8884 - val_accuracy: 0.6958\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7567 - accuracy: 0.7368 - val_loss: 0.9441 - val_accuracy: 0.6711\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.7462 - accuracy: 0.7422 - val_loss: 0.8755 - val_accuracy: 0.6983\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7454 - accuracy: 0.7420 - val_loss: 0.9383 - val_accuracy: 0.6723\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7376 - accuracy: 0.7429 - val_loss: 0.9506 - val_accuracy: 0.6748\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.7208 - accuracy: 0.7483 - val_loss: 0.8974 - val_accuracy: 0.6901\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.7179 - accuracy: 0.7509 - val_loss: 0.8796 - val_accuracy: 0.6961\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7094 - accuracy: 0.7520 - val_loss: 0.8810 - val_accuracy: 0.6933\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7095 - accuracy: 0.7535 - val_loss: 0.9683 - val_accuracy: 0.6726\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.7039 - accuracy: 0.7546 - val_loss: 0.9241 - val_accuracy: 0.6759\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6990 - accuracy: 0.7569 - val_loss: 0.8953 - val_accuracy: 0.6951\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6843 - accuracy: 0.7635 - val_loss: 0.8952 - val_accuracy: 0.6973\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6834 - accuracy: 0.7630 - val_loss: 0.9104 - val_accuracy: 0.6924\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6778 - accuracy: 0.7658 - val_loss: 0.9651 - val_accuracy: 0.6744\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6718 - accuracy: 0.7656 - val_loss: 0.8452 - val_accuracy: 0.7101\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6616 - accuracy: 0.7694 - val_loss: 0.8481 - val_accuracy: 0.7104\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6516 - accuracy: 0.7750 - val_loss: 0.8841 - val_accuracy: 0.6966\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6537 - accuracy: 0.7726 - val_loss: 0.8943 - val_accuracy: 0.6904\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6451 - accuracy: 0.7742 - val_loss: 0.8809 - val_accuracy: 0.7000\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.6528 - accuracy: 0.7711 - val_loss: 0.8663 - val_accuracy: 0.7058\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6290 - accuracy: 0.7808 - val_loss: 0.9057 - val_accuracy: 0.7007\n",
      "Epoch 100/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6284 - accuracy: 0.7844 - val_loss: 0.8813 - val_accuracy: 0.7037\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6211 - accuracy: 0.7830 - val_loss: 0.8921 - val_accuracy: 0.6978\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6180 - accuracy: 0.7864 - val_loss: 0.8850 - val_accuracy: 0.7057\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.6107 - accuracy: 0.7865 - val_loss: 0.8785 - val_accuracy: 0.7072\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5949 - accuracy: 0.7930 - val_loss: 0.8972 - val_accuracy: 0.7000\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5998 - accuracy: 0.7902 - val_loss: 0.9173 - val_accuracy: 0.7021\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5910 - accuracy: 0.7948 - val_loss: 0.8922 - val_accuracy: 0.7009\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5924 - accuracy: 0.7947 - val_loss: 0.8908 - val_accuracy: 0.7053\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5981 - accuracy: 0.7938 - val_loss: 0.9078 - val_accuracy: 0.6939\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5703 - accuracy: 0.8007 - val_loss: 0.8556 - val_accuracy: 0.7146\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5674 - accuracy: 0.8016 - val_loss: 0.9355 - val_accuracy: 0.6952\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5666 - accuracy: 0.8017 - val_loss: 0.9375 - val_accuracy: 0.6985\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.5576 - accuracy: 0.8064 - val_loss: 0.8996 - val_accuracy: 0.7028\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5536 - accuracy: 0.8068 - val_loss: 0.9283 - val_accuracy: 0.7098\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5487 - accuracy: 0.8097 - val_loss: 0.8772 - val_accuracy: 0.7190\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5354 - accuracy: 0.8138 - val_loss: 0.8947 - val_accuracy: 0.7077\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5591 - accuracy: 0.8060 - val_loss: 0.8655 - val_accuracy: 0.7149\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5394 - accuracy: 0.8126 - val_loss: 0.9095 - val_accuracy: 0.7057\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5325 - accuracy: 0.8141 - val_loss: 0.9027 - val_accuracy: 0.7081\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5219 - accuracy: 0.8156 - val_loss: 0.8881 - val_accuracy: 0.7187\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5194 - accuracy: 0.8182 - val_loss: 0.9234 - val_accuracy: 0.7018\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.5178 - accuracy: 0.8189 - val_loss: 0.9216 - val_accuracy: 0.7052\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4979 - accuracy: 0.8262 - val_loss: 1.0080 - val_accuracy: 0.6811\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.5208 - accuracy: 0.8194 - val_loss: 0.9159 - val_accuracy: 0.7060\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4922 - accuracy: 0.8272 - val_loss: 0.9397 - val_accuracy: 0.6967\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4996 - accuracy: 0.8262 - val_loss: 1.0310 - val_accuracy: 0.6789\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4876 - accuracy: 0.8313 - val_loss: 0.9109 - val_accuracy: 0.7098\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4815 - accuracy: 0.8316 - val_loss: 0.8986 - val_accuracy: 0.7163\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4702 - accuracy: 0.8369 - val_loss: 0.9326 - val_accuracy: 0.7024\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4782 - accuracy: 0.8342 - val_loss: 0.9022 - val_accuracy: 0.7134\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4721 - accuracy: 0.8342 - val_loss: 0.9653 - val_accuracy: 0.7093\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4698 - accuracy: 0.8344 - val_loss: 0.9260 - val_accuracy: 0.7041\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4523 - accuracy: 0.8430 - val_loss: 0.9437 - val_accuracy: 0.7014\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4619 - accuracy: 0.8376 - val_loss: 0.9423 - val_accuracy: 0.7095\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4334 - accuracy: 0.8483 - val_loss: 0.8973 - val_accuracy: 0.7211\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4554 - accuracy: 0.8403 - val_loss: 0.9245 - val_accuracy: 0.7110\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4444 - accuracy: 0.8450 - val_loss: 0.9669 - val_accuracy: 0.7030\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4319 - accuracy: 0.8505 - val_loss: 1.0663 - val_accuracy: 0.6908\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4426 - accuracy: 0.8445 - val_loss: 1.0108 - val_accuracy: 0.6760\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4143 - accuracy: 0.8555 - val_loss: 1.0640 - val_accuracy: 0.6887\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4202 - accuracy: 0.8531 - val_loss: 1.1244 - val_accuracy: 0.6698\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.9506 - val_accuracy: 0.7112\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4062 - accuracy: 0.8577 - val_loss: 0.9839 - val_accuracy: 0.7066\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4153 - accuracy: 0.8523 - val_loss: 1.0096 - val_accuracy: 0.6930\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4007 - accuracy: 0.8606 - val_loss: 0.9392 - val_accuracy: 0.7130\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3969 - accuracy: 0.8605 - val_loss: 0.9887 - val_accuracy: 0.7012\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3856 - accuracy: 0.8641 - val_loss: 1.0392 - val_accuracy: 0.7049\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.4155 - accuracy: 0.8565 - val_loss: 1.0210 - val_accuracy: 0.7033\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3748 - accuracy: 0.8675 - val_loss: 1.2393 - val_accuracy: 0.6572\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3828 - accuracy: 0.8664 - val_loss: 1.0024 - val_accuracy: 0.6984\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3770 - accuracy: 0.8677 - val_loss: 0.9900 - val_accuracy: 0.7129\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3855 - accuracy: 0.8642 - val_loss: 1.1046 - val_accuracy: 0.6902\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3630 - accuracy: 0.8745 - val_loss: 1.0345 - val_accuracy: 0.7091\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3633 - accuracy: 0.8733 - val_loss: 1.0957 - val_accuracy: 0.6956\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3584 - accuracy: 0.8735 - val_loss: 1.0211 - val_accuracy: 0.7083\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3518 - accuracy: 0.8753 - val_loss: 1.0270 - val_accuracy: 0.7087\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3632 - accuracy: 0.8730 - val_loss: 0.9860 - val_accuracy: 0.7157\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3476 - accuracy: 0.8785 - val_loss: 1.0329 - val_accuracy: 0.7090\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3340 - accuracy: 0.8834 - val_loss: 1.2365 - val_accuracy: 0.6739\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3425 - accuracy: 0.8806 - val_loss: 1.1285 - val_accuracy: 0.6969\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3284 - accuracy: 0.8859 - val_loss: 1.1192 - val_accuracy: 0.6913\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3298 - accuracy: 0.8841 - val_loss: 1.0721 - val_accuracy: 0.7152\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.3001 - accuracy: 0.8955 - val_loss: 1.1087 - val_accuracy: 0.6978\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3289 - accuracy: 0.8853 - val_loss: 1.1287 - val_accuracy: 0.6908\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3050 - accuracy: 0.8940 - val_loss: 1.1982 - val_accuracy: 0.6879\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3206 - accuracy: 0.8875 - val_loss: 1.0901 - val_accuracy: 0.7112\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3170 - accuracy: 0.8868 - val_loss: 1.0972 - val_accuracy: 0.7043\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2938 - accuracy: 0.8978 - val_loss: 1.0944 - val_accuracy: 0.7077\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3089 - accuracy: 0.8931 - val_loss: 1.1127 - val_accuracy: 0.7024\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.3157 - accuracy: 0.8891 - val_loss: 1.1486 - val_accuracy: 0.6989\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2719 - accuracy: 0.9043 - val_loss: 1.2057 - val_accuracy: 0.6985\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3023 - accuracy: 0.8932 - val_loss: 1.1268 - val_accuracy: 0.7003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2823 - accuracy: 0.9006 - val_loss: 1.1539 - val_accuracy: 0.7039\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2702 - accuracy: 0.9053 - val_loss: 1.1968 - val_accuracy: 0.6977\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2678 - accuracy: 0.9053 - val_loss: 1.1740 - val_accuracy: 0.6980\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2627 - accuracy: 0.9089 - val_loss: 1.2504 - val_accuracy: 0.6934\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2794 - accuracy: 0.9023 - val_loss: 1.2123 - val_accuracy: 0.6947\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2507 - accuracy: 0.9121 - val_loss: 1.2505 - val_accuracy: 0.6936\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2608 - accuracy: 0.9067 - val_loss: 1.3131 - val_accuracy: 0.6777\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2298 - accuracy: 0.9212 - val_loss: 1.2989 - val_accuracy: 0.7012\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2678 - accuracy: 0.9067 - val_loss: 1.2325 - val_accuracy: 0.7040\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2264 - accuracy: 0.9224 - val_loss: 1.3978 - val_accuracy: 0.6677\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2249 - accuracy: 0.9221 - val_loss: 1.3077 - val_accuracy: 0.6875\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2848 - accuracy: 0.9014 - val_loss: 1.2229 - val_accuracy: 0.7139\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2440 - accuracy: 0.9165 - val_loss: 1.2079 - val_accuracy: 0.7107\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2078 - accuracy: 0.9301 - val_loss: 1.3169 - val_accuracy: 0.6845\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2739 - accuracy: 0.9063 - val_loss: 1.1918 - val_accuracy: 0.7120\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2229 - accuracy: 0.9231 - val_loss: 1.4089 - val_accuracy: 0.6674\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2018 - accuracy: 0.9341 - val_loss: 1.7483 - val_accuracy: 0.5751\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2292 - accuracy: 0.9222 - val_loss: 1.2889 - val_accuracy: 0.7082\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2655 - accuracy: 0.9169 - val_loss: 1.2401 - val_accuracy: 0.7077\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2481 - accuracy: 0.9218 - val_loss: 1.1774 - val_accuracy: 0.6873\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1652 - accuracy: 0.9492 - val_loss: 1.3697 - val_accuracy: 0.6910\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2426 - accuracy: 0.9144 - val_loss: 1.2850 - val_accuracy: 0.6886\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1505 - accuracy: 0.9528 - val_loss: 1.4078 - val_accuracy: 0.6869\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1961 - accuracy: 0.9376 - val_loss: 1.3868 - val_accuracy: 0.7021\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2220 - accuracy: 0.9260 - val_loss: 1.3782 - val_accuracy: 0.6896\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1800 - accuracy: 0.9419 - val_loss: 1.3392 - val_accuracy: 0.7116\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2764 - accuracy: 0.9201 - val_loss: 1.0872 - val_accuracy: 0.6984\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1501 - accuracy: 0.9510 - val_loss: 1.4848 - val_accuracy: 0.6938\n",
      "Epoch 200/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2198 - accuracy: 0.9314 - val_loss: 1.1772 - val_accuracy: 0.7050\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1386 - accuracy: 0.9587 - val_loss: 1.7987 - val_accuracy: 0.6282\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1431 - accuracy: 0.9564 - val_loss: 1.4655 - val_accuracy: 0.7146\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0742 - accuracy: 0.9813 - val_loss: 1.5110 - val_accuracy: 0.7068\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0125 - accuracy: 0.7164 - val_loss: 1.0503 - val_accuracy: 0.6525\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4265 - accuracy: 0.8432 - val_loss: 1.2066 - val_accuracy: 0.7009\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2317 - accuracy: 0.9176 - val_loss: 1.2937 - val_accuracy: 0.7069\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1760 - accuracy: 0.9403 - val_loss: 1.3672 - val_accuracy: 0.7103\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1204 - accuracy: 0.9617 - val_loss: 1.4077 - val_accuracy: 0.7067\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1327 - accuracy: 0.9595 - val_loss: 1.5510 - val_accuracy: 0.6779\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1741 - accuracy: 0.9459 - val_loss: 1.6589 - val_accuracy: 0.6346\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1393 - accuracy: 0.9573 - val_loss: 1.4674 - val_accuracy: 0.6948\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0914 - accuracy: 0.9734 - val_loss: 1.5633 - val_accuracy: 0.6960\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1131 - accuracy: 0.9682 - val_loss: 1.4711 - val_accuracy: 0.7015\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0549 - accuracy: 0.9894 - val_loss: 1.6402 - val_accuracy: 0.7081\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0393 - accuracy: 0.9943 - val_loss: 1.6928 - val_accuracy: 0.7098\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0349 - accuracy: 0.9952 - val_loss: 1.7950 - val_accuracy: 0.7071\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0326 - accuracy: 0.9953 - val_loss: 1.8745 - val_accuracy: 0.7023\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 1.9956 - accuracy: 0.3489 - val_loss: 1.3710 - val_accuracy: 0.5172\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8421 - accuracy: 0.6973 - val_loss: 1.0455 - val_accuracy: 0.6808\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.4326 - accuracy: 0.8403 - val_loss: 1.2196 - val_accuracy: 0.6800\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.3139 - accuracy: 0.8840 - val_loss: 1.2868 - val_accuracy: 0.6894\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2428 - accuracy: 0.9118 - val_loss: 1.3145 - val_accuracy: 0.6998\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1915 - accuracy: 0.9299 - val_loss: 1.5006 - val_accuracy: 0.6912\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1741 - accuracy: 0.9396 - val_loss: 1.4802 - val_accuracy: 0.6824\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1090 - accuracy: 0.9653 - val_loss: 1.5667 - val_accuracy: 0.6937\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1622 - accuracy: 0.9556 - val_loss: 2.1782 - val_accuracy: 0.5550\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.2097 - accuracy: 0.9325 - val_loss: 1.4635 - val_accuracy: 0.6963\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0981 - accuracy: 0.9711 - val_loss: 1.6117 - val_accuracy: 0.7099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0481 - accuracy: 0.9905 - val_loss: 1.6489 - val_accuracy: 0.7107\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0359 - accuracy: 0.9951 - val_loss: 1.7376 - val_accuracy: 0.7068\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0314 - accuracy: 0.9959 - val_loss: 1.8124 - val_accuracy: 0.7115\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0258 - accuracy: 0.9975 - val_loss: 1.8519 - val_accuracy: 0.7109\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0210 - accuracy: 0.9989 - val_loss: 1.9394 - val_accuracy: 0.7077\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0184 - accuracy: 0.9992 - val_loss: 1.9552 - val_accuracy: 0.7107\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0161 - accuracy: 0.9994 - val_loss: 2.0041 - val_accuracy: 0.7113\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0139 - accuracy: 0.9997 - val_loss: 2.0589 - val_accuracy: 0.7101\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0122 - accuracy: 0.9997 - val_loss: 2.0859 - val_accuracy: 0.7089\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0111 - accuracy: 0.9998 - val_loss: 2.1162 - val_accuracy: 0.7091\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0098 - accuracy: 0.9999 - val_loss: 2.1692 - val_accuracy: 0.7086\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: 2.1910 - val_accuracy: 0.7110\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.2188 - val_accuracy: 0.7096\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.2567 - val_accuracy: 0.7091\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.2819 - val_accuracy: 0.7084\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2946 - val_accuracy: 0.7087\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.3281 - val_accuracy: 0.7102\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.3585 - val_accuracy: 0.7108\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3765 - val_accuracy: 0.7098\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.4060 - val_accuracy: 0.7117\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4241 - val_accuracy: 0.7098\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.4501 - val_accuracy: 0.7108\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.4686 - val_accuracy: 0.7101\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4835 - val_accuracy: 0.7088\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5098 - val_accuracy: 0.7095\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.5237 - val_accuracy: 0.7095\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5420 - val_accuracy: 0.7104\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5644 - val_accuracy: 0.7111\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5758 - val_accuracy: 0.7118\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5888 - val_accuracy: 0.7102\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.7117\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6221 - val_accuracy: 0.7095\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6414 - val_accuracy: 0.7104\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6562 - val_accuracy: 0.7105\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6657 - val_accuracy: 0.7097\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6804 - val_accuracy: 0.7092\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6930 - val_accuracy: 0.7114\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.7107\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7207 - val_accuracy: 0.7106\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7331 - val_accuracy: 0.7097\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7507 - val_accuracy: 0.7116\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7526 - val_accuracy: 0.7106\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7685 - val_accuracy: 0.7111\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.7101\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.7098\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.7103\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8118 - val_accuracy: 0.7105\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8210 - val_accuracy: 0.7103\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8369 - val_accuracy: 0.7101\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8479 - val_accuracy: 0.7104\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8530 - val_accuracy: 0.7096\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8676 - val_accuracy: 0.7106\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8764 - val_accuracy: 0.7102\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8799 - val_accuracy: 0.7100\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8920 - val_accuracy: 0.7108\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9046 - val_accuracy: 0.7107\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.7101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9232 - val_accuracy: 0.7104\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.7094\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9396 - val_accuracy: 0.7104\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9510 - val_accuracy: 0.7093\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9551 - val_accuracy: 0.7102\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9642 - val_accuracy: 0.7101\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9732 - val_accuracy: 0.7098\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9820 - val_accuracy: 0.7101\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9910 - val_accuracy: 0.7099\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0009 - val_accuracy: 0.7095\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0077 - val_accuracy: 0.7103\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0166 - val_accuracy: 0.7096\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0200 - val_accuracy: 0.7095\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0281 - val_accuracy: 0.7091\n",
      "Epoch 300/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0376 - val_accuracy: 0.7092\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0419 - val_accuracy: 0.7095\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0493 - val_accuracy: 0.7098\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0600 - val_accuracy: 0.7093\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0658 - val_accuracy: 0.7090\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0740 - val_accuracy: 0.7101\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0804 - val_accuracy: 0.7097\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0854 - val_accuracy: 0.7098\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 9.9120e-04 - accuracy: 1.0000 - val_loss: 3.0922 - val_accuracy: 0.7101\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.7567e-04 - accuracy: 1.0000 - val_loss: 3.0978 - val_accuracy: 0.7093\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 9.6152e-04 - accuracy: 1.0000 - val_loss: 3.1079 - val_accuracy: 0.7092\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 9.4731e-04 - accuracy: 1.0000 - val_loss: 3.1099 - val_accuracy: 0.7094\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 9.3223e-04 - accuracy: 1.0000 - val_loss: 3.1179 - val_accuracy: 0.7095\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 9.2150e-04 - accuracy: 1.0000 - val_loss: 3.1242 - val_accuracy: 0.7094\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 9.0741e-04 - accuracy: 1.0000 - val_loss: 3.1283 - val_accuracy: 0.7086\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 8.9368e-04 - accuracy: 1.0000 - val_loss: 3.1379 - val_accuracy: 0.7099\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 8.8269e-04 - accuracy: 1.0000 - val_loss: 3.1437 - val_accuracy: 0.7096\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 8.7006e-04 - accuracy: 1.0000 - val_loss: 3.1499 - val_accuracy: 0.7091\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 8.5743e-04 - accuracy: 1.0000 - val_loss: 3.1583 - val_accuracy: 0.7103\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 8.4617e-04 - accuracy: 1.0000 - val_loss: 3.1576 - val_accuracy: 0.7097\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 8.3305e-04 - accuracy: 1.0000 - val_loss: 3.1695 - val_accuracy: 0.7089\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 8.2261e-04 - accuracy: 1.0000 - val_loss: 3.1736 - val_accuracy: 0.7089\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 8.1211e-04 - accuracy: 1.0000 - val_loss: 3.1802 - val_accuracy: 0.7092\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 8.0217e-04 - accuracy: 1.0000 - val_loss: 3.1850 - val_accuracy: 0.7095\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.9094e-04 - accuracy: 1.0000 - val_loss: 3.1915 - val_accuracy: 0.7097\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.8141e-04 - accuracy: 1.0000 - val_loss: 3.1991 - val_accuracy: 0.7093\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 7.7206e-04 - accuracy: 1.0000 - val_loss: 3.2036 - val_accuracy: 0.7095\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 7.6285e-04 - accuracy: 1.0000 - val_loss: 3.2076 - val_accuracy: 0.7096\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.5210e-04 - accuracy: 1.0000 - val_loss: 3.2137 - val_accuracy: 0.7092\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 7.4297e-04 - accuracy: 1.0000 - val_loss: 3.2195 - val_accuracy: 0.7098\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.3484e-04 - accuracy: 1.0000 - val_loss: 3.2231 - val_accuracy: 0.7087\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 7.2518e-04 - accuracy: 1.0000 - val_loss: 3.2297 - val_accuracy: 0.7097\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.1638e-04 - accuracy: 1.0000 - val_loss: 3.2362 - val_accuracy: 0.7097\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.0827e-04 - accuracy: 1.0000 - val_loss: 3.2416 - val_accuracy: 0.7096\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 7.0053e-04 - accuracy: 1.0000 - val_loss: 3.2455 - val_accuracy: 0.7098\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.9291e-04 - accuracy: 1.0000 - val_loss: 3.2495 - val_accuracy: 0.7090\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.8411e-04 - accuracy: 1.0000 - val_loss: 3.2553 - val_accuracy: 0.7094\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.7624e-04 - accuracy: 1.0000 - val_loss: 3.2611 - val_accuracy: 0.7097\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.6834e-04 - accuracy: 1.0000 - val_loss: 3.2660 - val_accuracy: 0.7099\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.6066e-04 - accuracy: 1.0000 - val_loss: 3.2711 - val_accuracy: 0.7090\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.5410e-04 - accuracy: 1.0000 - val_loss: 3.2795 - val_accuracy: 0.7089\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.4686e-04 - accuracy: 1.0000 - val_loss: 3.2818 - val_accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.3990e-04 - accuracy: 1.0000 - val_loss: 3.2843 - val_accuracy: 0.7095\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.3303e-04 - accuracy: 1.0000 - val_loss: 3.2895 - val_accuracy: 0.7094\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.2586e-04 - accuracy: 1.0000 - val_loss: 3.2931 - val_accuracy: 0.7099\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.1919e-04 - accuracy: 1.0000 - val_loss: 3.2991 - val_accuracy: 0.7090\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 6.1285e-04 - accuracy: 1.0000 - val_loss: 3.3078 - val_accuracy: 0.7092\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 6.0662e-04 - accuracy: 1.0000 - val_loss: 3.3092 - val_accuracy: 0.7097\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 6.0020e-04 - accuracy: 1.0000 - val_loss: 3.3141 - val_accuracy: 0.7092\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.9410e-04 - accuracy: 1.0000 - val_loss: 3.3188 - val_accuracy: 0.7097\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 5.8842e-04 - accuracy: 1.0000 - val_loss: 3.3220 - val_accuracy: 0.7097\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.8223e-04 - accuracy: 1.0000 - val_loss: 3.3279 - val_accuracy: 0.7094\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.7661e-04 - accuracy: 1.0000 - val_loss: 3.3319 - val_accuracy: 0.7092\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.7020e-04 - accuracy: 1.0000 - val_loss: 3.3360 - val_accuracy: 0.7093\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.6533e-04 - accuracy: 1.0000 - val_loss: 3.3389 - val_accuracy: 0.7096\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.5933e-04 - accuracy: 1.0000 - val_loss: 3.3420 - val_accuracy: 0.7092\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.5371e-04 - accuracy: 1.0000 - val_loss: 3.3489 - val_accuracy: 0.7091\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 5.4892e-04 - accuracy: 1.0000 - val_loss: 3.3552 - val_accuracy: 0.7093\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.4341e-04 - accuracy: 1.0000 - val_loss: 3.3562 - val_accuracy: 0.7091\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.3816e-04 - accuracy: 1.0000 - val_loss: 3.3614 - val_accuracy: 0.7091\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.3298e-04 - accuracy: 1.0000 - val_loss: 3.3652 - val_accuracy: 0.7093\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 5.2889e-04 - accuracy: 1.0000 - val_loss: 3.3696 - val_accuracy: 0.7089\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 5.2355e-04 - accuracy: 1.0000 - val_loss: 3.3732 - val_accuracy: 0.7090\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 5.1870e-04 - accuracy: 1.0000 - val_loss: 3.3795 - val_accuracy: 0.7091\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.1405e-04 - accuracy: 1.0000 - val_loss: 3.3829 - val_accuracy: 0.7094\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 5.0931e-04 - accuracy: 1.0000 - val_loss: 3.3870 - val_accuracy: 0.7088\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 5.0506e-04 - accuracy: 1.0000 - val_loss: 3.3903 - val_accuracy: 0.7094\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 5.0006e-04 - accuracy: 1.0000 - val_loss: 3.3953 - val_accuracy: 0.7084\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.9637e-04 - accuracy: 1.0000 - val_loss: 3.3982 - val_accuracy: 0.7090\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.9112e-04 - accuracy: 1.0000 - val_loss: 3.4018 - val_accuracy: 0.7090\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.8696e-04 - accuracy: 1.0000 - val_loss: 3.4084 - val_accuracy: 0.7088\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.8254e-04 - accuracy: 1.0000 - val_loss: 3.4106 - val_accuracy: 0.7088\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.7823e-04 - accuracy: 1.0000 - val_loss: 3.4149 - val_accuracy: 0.7091\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.7383e-04 - accuracy: 1.0000 - val_loss: 3.4182 - val_accuracy: 0.7094\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.7044e-04 - accuracy: 1.0000 - val_loss: 3.4211 - val_accuracy: 0.7090\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.6629e-04 - accuracy: 1.0000 - val_loss: 3.4275 - val_accuracy: 0.7089\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.6270e-04 - accuracy: 1.0000 - val_loss: 3.4311 - val_accuracy: 0.7093\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.5790e-04 - accuracy: 1.0000 - val_loss: 3.4302 - val_accuracy: 0.7090\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.5511e-04 - accuracy: 1.0000 - val_loss: 3.4355 - val_accuracy: 0.7089\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.5101e-04 - accuracy: 1.0000 - val_loss: 3.4399 - val_accuracy: 0.7090\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.4757e-04 - accuracy: 1.0000 - val_loss: 3.4450 - val_accuracy: 0.7084\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.4356e-04 - accuracy: 1.0000 - val_loss: 3.4491 - val_accuracy: 0.7085\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.4048e-04 - accuracy: 1.0000 - val_loss: 3.4503 - val_accuracy: 0.7085\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.3690e-04 - accuracy: 1.0000 - val_loss: 3.4562 - val_accuracy: 0.7085\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.3336e-04 - accuracy: 1.0000 - val_loss: 3.4586 - val_accuracy: 0.7087\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.2954e-04 - accuracy: 1.0000 - val_loss: 3.4628 - val_accuracy: 0.7092\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.2616e-04 - accuracy: 1.0000 - val_loss: 3.4642 - val_accuracy: 0.7092\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.2308e-04 - accuracy: 1.0000 - val_loss: 3.4676 - val_accuracy: 0.7088\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.1992e-04 - accuracy: 1.0000 - val_loss: 3.4731 - val_accuracy: 0.7088\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.1669e-04 - accuracy: 1.0000 - val_loss: 3.4751 - val_accuracy: 0.7087\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 4.1326e-04 - accuracy: 1.0000 - val_loss: 3.4779 - val_accuracy: 0.7087\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.1030e-04 - accuracy: 1.0000 - val_loss: 3.4822 - val_accuracy: 0.7091\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 4.0690e-04 - accuracy: 1.0000 - val_loss: 3.4866 - val_accuracy: 0.7083\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.0386e-04 - accuracy: 1.0000 - val_loss: 3.4897 - val_accuracy: 0.7086\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 4.0091e-04 - accuracy: 1.0000 - val_loss: 3.4921 - val_accuracy: 0.7086\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.9789e-04 - accuracy: 1.0000 - val_loss: 3.4961 - val_accuracy: 0.7086\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.9507e-04 - accuracy: 1.0000 - val_loss: 3.4996 - val_accuracy: 0.7088\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 43ms/step - loss: 3.9212e-04 - accuracy: 1.0000 - val_loss: 3.5029 - val_accuracy: 0.7084\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.8932e-04 - accuracy: 1.0000 - val_loss: 3.5057 - val_accuracy: 0.7086\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.8652e-04 - accuracy: 1.0000 - val_loss: 3.5090 - val_accuracy: 0.7088\n",
      "Epoch 400/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.8342e-04 - accuracy: 1.0000 - val_loss: 3.5126 - val_accuracy: 0.7086\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.8103e-04 - accuracy: 1.0000 - val_loss: 3.5151 - val_accuracy: 0.7082\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.7800e-04 - accuracy: 1.0000 - val_loss: 3.5190 - val_accuracy: 0.7086\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.7535e-04 - accuracy: 1.0000 - val_loss: 3.5204 - val_accuracy: 0.7078\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.7302e-04 - accuracy: 1.0000 - val_loss: 3.5270 - val_accuracy: 0.7081\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.7022e-04 - accuracy: 1.0000 - val_loss: 3.5288 - val_accuracy: 0.7084\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.6741e-04 - accuracy: 1.0000 - val_loss: 3.5320 - val_accuracy: 0.7084\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.6500e-04 - accuracy: 1.0000 - val_loss: 3.5361 - val_accuracy: 0.7082\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.6237e-04 - accuracy: 1.0000 - val_loss: 3.5363 - val_accuracy: 0.7083\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.6011e-04 - accuracy: 1.0000 - val_loss: 3.5429 - val_accuracy: 0.7079\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.5775e-04 - accuracy: 1.0000 - val_loss: 3.5447 - val_accuracy: 0.7076\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.5495e-04 - accuracy: 1.0000 - val_loss: 3.5464 - val_accuracy: 0.7085\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.5298e-04 - accuracy: 1.0000 - val_loss: 3.5485 - val_accuracy: 0.7078\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.5039e-04 - accuracy: 1.0000 - val_loss: 3.5530 - val_accuracy: 0.7081\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.4810e-04 - accuracy: 1.0000 - val_loss: 3.5561 - val_accuracy: 0.7082\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.4579e-04 - accuracy: 1.0000 - val_loss: 3.5595 - val_accuracy: 0.7084\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.4327e-04 - accuracy: 1.0000 - val_loss: 3.5633 - val_accuracy: 0.7082\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.4101e-04 - accuracy: 1.0000 - val_loss: 3.5640 - val_accuracy: 0.7081\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.3895e-04 - accuracy: 1.0000 - val_loss: 3.5672 - val_accuracy: 0.7082\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.3662e-04 - accuracy: 1.0000 - val_loss: 3.5707 - val_accuracy: 0.7083\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.3462e-04 - accuracy: 1.0000 - val_loss: 3.5749 - val_accuracy: 0.7081\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.3227e-04 - accuracy: 1.0000 - val_loss: 3.5759 - val_accuracy: 0.7079\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.3041e-04 - accuracy: 1.0000 - val_loss: 3.5796 - val_accuracy: 0.7078\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.2825e-04 - accuracy: 1.0000 - val_loss: 3.5820 - val_accuracy: 0.7076\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.2598e-04 - accuracy: 1.0000 - val_loss: 3.5845 - val_accuracy: 0.7081\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.2410e-04 - accuracy: 1.0000 - val_loss: 3.5876 - val_accuracy: 0.7079\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.2192e-04 - accuracy: 1.0000 - val_loss: 3.5912 - val_accuracy: 0.7080\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.1974e-04 - accuracy: 1.0000 - val_loss: 3.5931 - val_accuracy: 0.7077\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.1777e-04 - accuracy: 1.0000 - val_loss: 3.5970 - val_accuracy: 0.7072\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.1590e-04 - accuracy: 1.0000 - val_loss: 3.5994 - val_accuracy: 0.7076\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1404e-04 - accuracy: 1.0000 - val_loss: 3.6010 - val_accuracy: 0.7079\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1186e-04 - accuracy: 1.0000 - val_loss: 3.6064 - val_accuracy: 0.7073\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.1009e-04 - accuracy: 1.0000 - val_loss: 3.6087 - val_accuracy: 0.7075\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 3.0845e-04 - accuracy: 1.0000 - val_loss: 3.6101 - val_accuracy: 0.7076\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.0625e-04 - accuracy: 1.0000 - val_loss: 3.6118 - val_accuracy: 0.7080\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 3.0450e-04 - accuracy: 1.0000 - val_loss: 3.6164 - val_accuracy: 0.7078\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.0281e-04 - accuracy: 1.0000 - val_loss: 3.6195 - val_accuracy: 0.7076\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 3.0088e-04 - accuracy: 1.0000 - val_loss: 3.6239 - val_accuracy: 0.7074\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9912e-04 - accuracy: 1.0000 - val_loss: 3.6247 - val_accuracy: 0.7070\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9736e-04 - accuracy: 1.0000 - val_loss: 3.6273 - val_accuracy: 0.7075\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9580e-04 - accuracy: 1.0000 - val_loss: 3.6302 - val_accuracy: 0.7079\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9406e-04 - accuracy: 1.0000 - val_loss: 3.6322 - val_accuracy: 0.7077\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9216e-04 - accuracy: 1.0000 - val_loss: 3.6343 - val_accuracy: 0.7070\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.9050e-04 - accuracy: 1.0000 - val_loss: 3.6371 - val_accuracy: 0.7074\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.8886e-04 - accuracy: 1.0000 - val_loss: 3.6405 - val_accuracy: 0.7075\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.8724e-04 - accuracy: 1.0000 - val_loss: 3.6419 - val_accuracy: 0.7077\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.8556e-04 - accuracy: 1.0000 - val_loss: 3.6450 - val_accuracy: 0.7074\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.8365e-04 - accuracy: 1.0000 - val_loss: 3.6474 - val_accuracy: 0.7070\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.8234e-04 - accuracy: 1.0000 - val_loss: 3.6489 - val_accuracy: 0.7070\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.8068e-04 - accuracy: 1.0000 - val_loss: 3.6524 - val_accuracy: 0.7072\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.7921e-04 - accuracy: 1.0000 - val_loss: 3.6544 - val_accuracy: 0.7074\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.7749e-04 - accuracy: 1.0000 - val_loss: 3.6580 - val_accuracy: 0.7076\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 43ms/step - loss: 2.7606e-04 - accuracy: 1.0000 - val_loss: 3.6606 - val_accuracy: 0.7078\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.7447e-04 - accuracy: 1.0000 - val_loss: 3.6628 - val_accuracy: 0.7077\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.7295e-04 - accuracy: 1.0000 - val_loss: 3.6646 - val_accuracy: 0.7071\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.7154e-04 - accuracy: 1.0000 - val_loss: 3.6674 - val_accuracy: 0.7069\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.7009e-04 - accuracy: 1.0000 - val_loss: 3.6705 - val_accuracy: 0.7071\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.6861e-04 - accuracy: 1.0000 - val_loss: 3.6723 - val_accuracy: 0.7070\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.6715e-04 - accuracy: 1.0000 - val_loss: 3.6773 - val_accuracy: 0.7075\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.6554e-04 - accuracy: 1.0000 - val_loss: 3.6789 - val_accuracy: 0.7073\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.6419e-04 - accuracy: 1.0000 - val_loss: 3.6792 - val_accuracy: 0.7073\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.6284e-04 - accuracy: 1.0000 - val_loss: 3.6821 - val_accuracy: 0.7076\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.6136e-04 - accuracy: 1.0000 - val_loss: 3.6841 - val_accuracy: 0.7068\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5994e-04 - accuracy: 1.0000 - val_loss: 3.6879 - val_accuracy: 0.7074\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.5865e-04 - accuracy: 1.0000 - val_loss: 3.6906 - val_accuracy: 0.7069\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 2.5718e-04 - accuracy: 1.0000 - val_loss: 3.6918 - val_accuracy: 0.7071\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.5595e-04 - accuracy: 1.0000 - val_loss: 3.6945 - val_accuracy: 0.7071\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.5466e-04 - accuracy: 1.0000 - val_loss: 3.6967 - val_accuracy: 0.7068\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.5338e-04 - accuracy: 1.0000 - val_loss: 3.6992 - val_accuracy: 0.7071\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.5198e-04 - accuracy: 1.0000 - val_loss: 3.7007 - val_accuracy: 0.7073\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.5069e-04 - accuracy: 1.0000 - val_loss: 3.7041 - val_accuracy: 0.7078\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.4941e-04 - accuracy: 1.0000 - val_loss: 3.7067 - val_accuracy: 0.7071\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.4803e-04 - accuracy: 1.0000 - val_loss: 3.7102 - val_accuracy: 0.7077\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.4696e-04 - accuracy: 1.0000 - val_loss: 3.7111 - val_accuracy: 0.7073\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.4556e-04 - accuracy: 1.0000 - val_loss: 3.7145 - val_accuracy: 0.7068\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.4450e-04 - accuracy: 1.0000 - val_loss: 3.7156 - val_accuracy: 0.7068\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.4308e-04 - accuracy: 1.0000 - val_loss: 3.7159 - val_accuracy: 0.7071\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.4178e-04 - accuracy: 1.0000 - val_loss: 3.7207 - val_accuracy: 0.7067\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.4084e-04 - accuracy: 1.0000 - val_loss: 3.7226 - val_accuracy: 0.7069\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.3936e-04 - accuracy: 1.0000 - val_loss: 3.7239 - val_accuracy: 0.7069\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.3835e-04 - accuracy: 1.0000 - val_loss: 3.7271 - val_accuracy: 0.7069\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.3726e-04 - accuracy: 1.0000 - val_loss: 3.7293 - val_accuracy: 0.7074\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.3595e-04 - accuracy: 1.0000 - val_loss: 3.7306 - val_accuracy: 0.7072\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.3471e-04 - accuracy: 1.0000 - val_loss: 3.7336 - val_accuracy: 0.7070\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.3389e-04 - accuracy: 1.0000 - val_loss: 3.7364 - val_accuracy: 0.7072\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.3260e-04 - accuracy: 1.0000 - val_loss: 3.7383 - val_accuracy: 0.7068\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.3149e-04 - accuracy: 1.0000 - val_loss: 3.7390 - val_accuracy: 0.7066\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.3037e-04 - accuracy: 1.0000 - val_loss: 3.7421 - val_accuracy: 0.7069\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2931e-04 - accuracy: 1.0000 - val_loss: 3.7441 - val_accuracy: 0.7072\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.2813e-04 - accuracy: 1.0000 - val_loss: 3.7468 - val_accuracy: 0.7065\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2708e-04 - accuracy: 1.0000 - val_loss: 3.7483 - val_accuracy: 0.7069\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.2594e-04 - accuracy: 1.0000 - val_loss: 3.7500 - val_accuracy: 0.7066\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2499e-04 - accuracy: 1.0000 - val_loss: 3.7532 - val_accuracy: 0.7068\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2386e-04 - accuracy: 1.0000 - val_loss: 3.7536 - val_accuracy: 0.7065\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.2277e-04 - accuracy: 1.0000 - val_loss: 3.7573 - val_accuracy: 0.7065\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 3.7593 - val_accuracy: 0.7068\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 2.2070e-04 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.7066\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 2.1970e-04 - accuracy: 1.0000 - val_loss: 3.7638 - val_accuracy: 0.7066\n",
      "Epoch 498/500\n",
      "37/49 [=====================>........] - ETA: 0s - loss: 2.2023e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# check the training accuracy\n",
    "origin_dpsgd = dpsgd\n",
    "parameter_list = {}\n",
    "accuracies = {}\n",
    "#for model_type in [\"mnist\", \"mnist+tied_bias\", \"mnist+untied_bias\"]:\n",
    "for model_type in [\"cifar10+tied_bias\"]:\n",
    "    file_name = model_type + \"_accuracy\"\n",
    "    if model_type == \"cifar10+tied_bias+noise_input\":\n",
    "        dpsgd = False\n",
    "    else:\n",
    "        dpsgd = origin_dpsgd\n",
    "    model = build_models(model_type)\n",
    "    if dpsgd:\n",
    "        optimizer = FixedDPKerasSGDOptimizer(\n",
    "            batch_size = batch_size,\n",
    "            num_parameters = num_parameters,\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            var_list = model.trainable_variables,\n",
    "            #num_microbatches=batch_size//microbatch_size,\n",
    "            microbatch_size = microbatch_size,\n",
    "            learning_rate=learning_rate)\n",
    "        # Compute vector of per-example loss rather than its mean over a minibatch.\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compile model with Keras\n",
    "    checkpoint_filepath = \"./dp_data/\"+file_name\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      save_weights_only=True,\n",
    "      monitor='val_accuracy',\n",
    "      mode='max',\n",
    "      save_best_only=True)\n",
    "    #early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    ##    monitor='val_loss', min_delta=0, patience=5, verbose=0,\n",
    "    #    mode='auto', baseline=None, restore_best_weights=True\n",
    "    #)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    # Train model with Keras\n",
    "    if dpsgd:\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                epochs=epochs,\n",
    "                validation_data=(test_data, test_labels),\n",
    "                batch_size=microbatch_size, \n",
    "                callbacks = [model_checkpoint_callback], workers=1) # , early_stopping_callback\n",
    "    else:\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                epochs=epochs,\n",
    "                validation_data=(test_data, test_labels),\n",
    "                batch_size=batch_size, \n",
    "                callbacks = [model_checkpoint_callback], workers=1) # , early_stopping_callback\n",
    "    \n",
    "    #evaluated_result = model.evaluate(\n",
    "    #    x=test_data, y=test_labels, batch_size=None, verbose=1, sample_weight=None, steps=None,\n",
    "    #    callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False,\n",
    "    #    return_dict=True)\n",
    "    if model_type not in accuracies.keys():\n",
    "        accuracies[model_type] = []\n",
    "    accuracies[model_type].append(history)\n",
    "    #accuracies[model_type].append(evaluated_result[\"accuracy\"])\n",
    "\n",
    "# Compute the privacy budget expended.\n",
    "#if dpsgd:\n",
    "#    eps = compute_epsilon(epochs * 60000 // batch_size)\n",
    "#    print('For delta=1e-5, the current epsilon is: %.2f' % eps)\n",
    "#else:\n",
    "#    print('Trained with vanilla non-private SGD optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_accuracies = dict()\n",
    "for key in accuracies.keys():   \n",
    "    processed_accuracies[key] = accuracies[key][0].history\n",
    "    \n",
    "import pickle\n",
    "file = open(\"dp_data/results/cifar10_accuracies_%.1f_%.1f_%.1f_%d\"%(learning_rate, noise_multiplier, l2_norm_clip, batch_size),\"wb\")\n",
    "pickle.dump(processed_accuracies, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed Label : skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_noise(x, clip, noise_multiplier):\n",
    "    def clip_features(x):\n",
    "        return tf.clip_by_global_norm([x], clip)[0][0]\n",
    "    clipped_features = tf.map_fn(clip_features, x)\n",
    "    # Add noise to summed gradients.\n",
    "    noise_stddev = clip * noise_multiplier\n",
    "    noise = tf.random.normal(tf.shape(input=clipped_features), stddev=noise_stddev)\n",
    "    return clipped_features + noise\n",
    "\n",
    "noisy_train_data = tf.map_fn(lambda x: clip_noise(x, l2_norm_clip, noise_multiplier), train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_accuracies = dict()\n",
    "for key in accuracies.keys():   \n",
    "    processed_accuracies[key] = accuracies[key][0].history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(processed_accuracies['sphinx+mnist+untied_bias']['accuracy'])\n",
    "plt.plot(processed_accuracies['sphinx+mnist+untied_bias']['val_accuracy'])\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"dp_data/results/accuracies_%.1f_%.1f_%.1f_%d\"%(learning_rate, noise_multiplier, l2_norm_clip, batch_size),\"wb\")\n",
    "pickle.dump(processed_accuracies, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the step-epsilon curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "try:\n",
    "    with open(\"dp_data/noise_epsilon_step\") as f:\n",
    "        epsilons = pickle.load(f)\n",
    "except:\n",
    "    training_data_size = 60000\n",
    "    max_step = 25000\n",
    "    epsilons = [[] for i in range(10)]\n",
    "    for noise_multiplier in range(0, 10, 1):\n",
    "        print(\"noise_multiplier:\", noise_multiplier)\n",
    "        for step in range(1, max_step, 10):\n",
    "            epsilons[noise_multiplier].append(compute_epsilon(step, batch_size/training_data_size, noise_multiplier))\n",
    "    file = open(\"dp_data/noise_epsilon_step_%d\"%batch_size,\"wb\")\n",
    "    pickle.dump(epsilons, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tied Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tied bias\n",
    "#for model_type in [\"mnist\", \"mnist+tied_bias\", \"mnist+untied_bias\"]:\n",
    "for model_type in [\"sphinx+mnist+tied_bias\", \"ALLnoise+mnist+tied_bias\",\"mnist+tied_bias\"]:\n",
    "    file_name = model_type + \"_accuracy\"\n",
    "    if model_type == \"mnist+tied_bias+noise_input\":\n",
    "        dpsgd = False\n",
    "    else:\n",
    "        dpsgd = True\n",
    "    model = build_models(model_type)\n",
    "    if dpsgd:\n",
    "        optimizer = FixedDPKerasSGDOptimizer(\n",
    "            batch_size = batch_size,\n",
    "            num_parameters = num_parameters,\n",
    "            l2_norm_clip=l2_norm_clip,\n",
    "            noise_multiplier=noise_multiplier,\n",
    "            var_list = model.trainable_variables,\n",
    "            #num_microbatches=batch_size//microbatch_size,\n",
    "            microbatch_size = microbatch_size,\n",
    "            learning_rate=learning_rate)\n",
    "        # Compute vector of per-example loss rather than its mean over a minibatch.\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compile model with Keras\n",
    "    checkpoint_filepath = \"./dp_data/\"+file_name\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      save_weights_only=True,\n",
    "      monitor='val_accuracy',\n",
    "      mode='max',\n",
    "      save_best_only=True)\n",
    "    #early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    ##    monitor='val_loss', min_delta=0, patience=5, verbose=0,\n",
    "    #    mode='auto', baseline=None, restore_best_weights=True\n",
    "    #)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    # Train model with Keras\n",
    "    if dpsgd:\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                epochs=epochs,\n",
    "                validation_data=(test_data, test_labels),\n",
    "                batch_size=microbatch_size, \n",
    "                callbacks = [model_checkpoint_callback], workers=1) # , early_stopping_callback\n",
    "    else:\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                epochs=epochs,\n",
    "                validation_data=(test_data, test_labels),\n",
    "                batch_size=batch_size, \n",
    "                callbacks = [model_checkpoint_callback], workers=1) # , early_stopping_callback\n",
    "    \n",
    "    #evaluated_result = model.evaluate(\n",
    "    #    x=test_data, y=test_labels, batch_size=None, verbose=1, sample_weight=None, steps=None,\n",
    "    #    callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False,\n",
    "    #    return_dict=True)\n",
    "    if model_type not in accuracies.keys():\n",
    "        accuracies[model_type] = []\n",
    "    accuracies[model_type].append(history)\n",
    "    #accuracies[model_type].append(evaluated_result[\"accuracy\"])\n",
    "\n",
    "# Compute the privacy budget expended.\n",
    "#if dpsgd:\n",
    "#    eps = compute_epsilon(epochs * 60000 // batch_size)\n",
    "#    print('For delta=1e-5, the current epsilon is: %.2f' % eps)\n",
    "#else:\n",
    "#    print('Trained with vanilla non-private SGD optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Using set_dashes() to modify dashing of an existing line\n",
    "for key in parameter_list.keys():\n",
    "    line1, = ax.plot(parameter_list[key],accuracies[key],  label=key)\n",
    "    line1.set_dashes([2, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee\n",
    "import pickle\n",
    "result = open(\"result\",\"wb\")\n",
    "pickle.dump(accuracies, result)\n",
    "pickle.dump(parameter_list, result)\n",
    "result.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open(\"result\", \"rb\")\n",
    "accuracies = pickle.load(result)\n",
    "parameter_list = pickle.load(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Using set_dashes() to modify dashing of an existing line\n",
    "line1, = ax.plot(parameter_list[\"linear\"],accuracies[\"linear\"],  label='Linear')\n",
    "line1.set_dashes([2, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break\n",
    "\n",
    "line2, = ax.plot(parameter_list[\"bias\"],  accuracies[\"bias\"], label='Bias')\n",
    "line2.set_dashes([2, 2, 10, 2])  # 2pt line, 2pt break, 10pt line, 2pt break\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "a = [tf.constant([2., 3, 4.], shape=(3,), dtype=tf.float32), tf.constant([3., 4, 5], shape=(3,), dtype=tf.float32), tf.constant([2., 3, 4.], shape=(3,), dtype=tf.float32)]\n",
    "b = tf.ones_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.linalg.global_norm(a[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.clip_by_global_norm(a, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "dpsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
